{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (106800, 15)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_sub_id</th>\n",
       "      <th>eeg_label_offset_seconds</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spectrogram_sub_id</th>\n",
       "      <th>spectrogram_label_offset_seconds</th>\n",
       "      <th>label_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127492639</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3887563113</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1142670488</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2718991173</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3080632009</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
       "0  1628180742           0                       0.0          353733   \n",
       "1  1628180742           1                       6.0          353733   \n",
       "2  1628180742           2                       8.0          353733   \n",
       "3  1628180742           3                      18.0          353733   \n",
       "4  1628180742           4                      24.0          353733   \n",
       "\n",
       "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
       "0                   0                               0.0   127492639   \n",
       "1                   1                               6.0  3887563113   \n",
       "2                   2                               8.0  1142670488   \n",
       "3                   3                              18.0  2718991173   \n",
       "4                   4                              24.0  3080632009   \n",
       "\n",
       "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       42516          Seizure             3         0         0          0   \n",
       "1       42516          Seizure             3         0         0          0   \n",
       "2       42516          Seizure             3         0         0          0   \n",
       "3       42516          Seizure             3         0         0          0   \n",
       "4       42516          Seizure             3         0         0          0   \n",
       "\n",
       "   grda_vote  other_vote  \n",
       "0          0           0  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "TARGETS = df.columns[-6:]\n",
    "print('Train shape:', df.shape )\n",
    "print('Targets', list(TARGETS))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train non-overlapp eeg_id shape: (17089, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>789577333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20230</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>LPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>14960202</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>5955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>618728447</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>38549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>52296320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1629671</td>\n",
       "      <td>2036345030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>37481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Seizure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1895581</td>\n",
       "      <td>128369999</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>47999</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2061593</td>\n",
       "      <td>320962633</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>1450.0</td>\n",
       "      <td>23828</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2078097</td>\n",
       "      <td>2074135650</td>\n",
       "      <td>3342.0</td>\n",
       "      <td>3342.0</td>\n",
       "      <td>61174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2366870</td>\n",
       "      <td>1232582129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2482631</td>\n",
       "      <td>978166025</td>\n",
       "      <td>1902.0</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>20606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2521897</td>\n",
       "      <td>673742515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>62117</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2918824</td>\n",
       "      <td>1211648246</td>\n",
       "      <td>3462.0</td>\n",
       "      <td>3462.0</td>\n",
       "      <td>14965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Seizure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3108700</td>\n",
       "      <td>223960986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3625731</td>\n",
       "      <td>2091405434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6935</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3851658</td>\n",
       "      <td>1331405712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3907459</td>\n",
       "      <td>1343094925</td>\n",
       "      <td>3688.0</td>\n",
       "      <td>3694.0</td>\n",
       "      <td>6489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>LRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4431217</td>\n",
       "      <td>1459125071</td>\n",
       "      <td>52.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>49713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4454049</td>\n",
       "      <td>1313185981</td>\n",
       "      <td>342.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>44475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4559645</td>\n",
       "      <td>1902315832</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>2436.0</td>\n",
       "      <td>22195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GRDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eeg_id  spectrogram_id     min     max  patient_id  seizure_vote  \\\n",
       "0    568657       789577333     0.0    16.0       20654      0.000000   \n",
       "1    582999      1552638400     0.0    38.0       20230      0.000000   \n",
       "2    642382        14960202  1008.0  1032.0        5955      0.000000   \n",
       "3    751790       618728447   908.0   908.0       38549      0.000000   \n",
       "4    778705        52296320     0.0     0.0       40955      0.000000   \n",
       "5   1629671      2036345030     0.0   160.0       37481      1.000000   \n",
       "6   1895581       128369999  1138.0  1138.0       47999      0.076923   \n",
       "7   2061593       320962633  1450.0  1450.0       23828      0.000000   \n",
       "8   2078097      2074135650  3342.0  3342.0       61174      0.000000   \n",
       "9   2366870      1232582129     0.0    30.0       23633      0.000000   \n",
       "10  2482631       978166025  1902.0  1944.0       20606      0.000000   \n",
       "11  2521897       673742515     0.0     4.0       62117      0.000000   \n",
       "12  2918824      1211648246  3462.0  3462.0       14965      1.000000   \n",
       "13  3108700       223960986     0.0     0.0       55677      0.000000   \n",
       "14  3625731      2091405434     0.0     0.0        6935      0.000000   \n",
       "15  3851658      1331405712     0.0     0.0       30631      0.000000   \n",
       "16  3907459      1343094925  3688.0  3694.0        6489      0.000000   \n",
       "17  4431217      1459125071    52.0   124.0       49713      0.000000   \n",
       "18  4454049      1313185981   342.0   380.0       44475      0.000000   \n",
       "19  4559645      1902315832  2436.0  2436.0       22195      0.000000   \n",
       "\n",
       "    lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote   target  \n",
       "0   0.000000  0.250000   0.000000   0.166667    0.583333    Other  \n",
       "1   0.857143  0.000000   0.071429   0.000000    0.071429      LPD  \n",
       "2   0.000000  0.000000   0.000000   0.000000    1.000000    Other  \n",
       "3   0.000000  1.000000   0.000000   0.000000    0.000000      GPD  \n",
       "4   0.000000  0.000000   0.000000   0.000000    1.000000    Other  \n",
       "5   0.000000  0.000000   0.000000   0.000000    0.000000  Seizure  \n",
       "6   0.000000  0.000000   0.000000   0.076923    0.846154    Other  \n",
       "7   0.000000  0.000000   0.000000   0.000000    1.000000    Other  \n",
       "8   0.000000  0.000000   0.000000   0.000000    1.000000    Other  \n",
       "9   0.333333  0.000000   0.000000   0.000000    0.666667    Other  \n",
       "10  0.000000  0.133333   0.066667   0.133333    0.666667    Other  \n",
       "11  0.000000  0.083333   0.083333   0.333333    0.500000    Other  \n",
       "12  0.000000  0.000000   0.000000   0.000000    0.000000  Seizure  \n",
       "13  0.000000  0.000000   0.000000   0.000000    1.000000    Other  \n",
       "14  0.000000  0.000000   0.000000   1.000000    0.000000     GRDA  \n",
       "15  0.000000  0.000000   1.000000   0.000000    0.000000     LRDA  \n",
       "16  0.000000  0.000000   0.666667   0.000000    0.333333     LRDA  \n",
       "17  1.000000  0.000000   0.000000   0.000000    0.000000      LPD  \n",
       "18  0.000000  0.666667   0.000000   0.000000    0.333333      GPD  \n",
       "19  0.000000  0.000000   0.000000   1.000000    0.000000     GRDA  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "    {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
    "train.columns = ['spectrogram_id','min']\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "    {'spectrogram_label_offset_seconds':'max'})\n",
    "train['max'] = tmp\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
    "train['patient_id'] = tmp\n",
    "\n",
    "tmp = df.groupby('eeg_id')[TARGETS].agg('sum')\n",
    "for t in TARGETS:\n",
    "    train[t] = tmp[t].values\n",
    "    \n",
    "y_data = train[TARGETS].values\n",
    "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "train[TARGETS] = y_data\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
    "train['target'] = tmp\n",
    "\n",
    "train = train.reset_index()\n",
    "print('Train non-overlapp eeg_id shape:', train.shape )\n",
    "\n",
    "train.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>LPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1629671</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Seizure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1895581</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2061593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2078097</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2366870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2482631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2521897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2918824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Seizure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3108700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3625731</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3851658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3907459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>LRDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4431217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>LPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4454049</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4559645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GRDA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0    568657      0.000000  0.000000  0.250000   0.000000   0.166667   \n",
       "1    582999      0.000000  0.857143  0.000000   0.071429   0.000000   \n",
       "2    642382      0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "3    751790      0.000000  0.000000  1.000000   0.000000   0.000000   \n",
       "4    778705      0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "5   1629671      1.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "6   1895581      0.076923  0.000000  0.000000   0.000000   0.076923   \n",
       "7   2061593      0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "8   2078097      0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "9   2366870      0.000000  0.333333  0.000000   0.000000   0.000000   \n",
       "10  2482631      0.000000  0.000000  0.133333   0.066667   0.133333   \n",
       "11  2521897      0.000000  0.000000  0.083333   0.083333   0.333333   \n",
       "12  2918824      1.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "13  3108700      0.000000  0.000000  0.000000   0.000000   0.000000   \n",
       "14  3625731      0.000000  0.000000  0.000000   0.000000   1.000000   \n",
       "15  3851658      0.000000  0.000000  0.000000   1.000000   0.000000   \n",
       "16  3907459      0.000000  0.000000  0.000000   0.666667   0.000000   \n",
       "17  4431217      0.000000  1.000000  0.000000   0.000000   0.000000   \n",
       "18  4454049      0.000000  0.000000  0.666667   0.000000   0.000000   \n",
       "19  4559645      0.000000  0.000000  0.000000   0.000000   1.000000   \n",
       "\n",
       "    other_vote   target  \n",
       "0     0.583333    Other  \n",
       "1     0.071429      LPD  \n",
       "2     1.000000    Other  \n",
       "3     0.000000      GPD  \n",
       "4     1.000000    Other  \n",
       "5     0.000000  Seizure  \n",
       "6     0.846154    Other  \n",
       "7     1.000000    Other  \n",
       "8     1.000000    Other  \n",
       "9     0.666667    Other  \n",
       "10    0.666667    Other  \n",
       "11    0.500000    Other  \n",
       "12    0.000000  Seizure  \n",
       "13    1.000000    Other  \n",
       "14    0.000000     GRDA  \n",
       "15    0.000000     LRDA  \n",
       "16    0.333333     LRDA  \n",
       "17    0.000000      LPD  \n",
       "18    0.333333      GPD  \n",
       "19    0.000000     GRDA  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "ycol = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "cd = {'Seizure': 'seizure_vote', 'GPD': 'gpd_vote', 'LRDA': 'lrda_vote', 'Other': 'other_vote', 'GRDA': 'grda_vote', 'LPD': 'lpd_vote'}\n",
    "\n",
    "\n",
    "eeg_id_col = train.iloc[:, 0]  \n",
    "prob_cols = train.iloc[:, -7:-1]  \n",
    "label_col = train.iloc[:, -1] \n",
    "\n",
    "\n",
    "prob_cols = prob_cols.astype(\"float32\")\n",
    "\n",
    "\n",
    "prob_cols_normalized = prob_cols.div(prob_cols.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "normalized_data = pd.concat([eeg_id_col, prob_cols_normalized, label_col], axis=1)\n",
    "\n",
    "normalized_data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data.to_csv(\"normalized_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EEG_PATH = 'train_eegs/'\n",
    "train_path = 'normalized_data.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from scipy.signal import butter, sosfilt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from EGGDataset import EEGDataset\n",
    "dataset = EEGDataset(train_path, EEG_PATH)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True, num_workers=2, prefetch_factor=2, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1: X shape torch.Size([8, 10000]), y shape torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "X, y = dataset[0]\n",
    "print(f\"Sample {0 + 1}: X shape {X.shape}, y shape {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNLSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=8, num_classes=6):\n",
    "        super(CNNLSTM, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.dropout2 = nn.Dropout(p=0.75)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.lstm1 = nn.LSTM(input_size=64, hidden_size=128, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(128 * 2, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(128 * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        # reshape for LSTM\n",
    "        batch_size, channels, seq_length = x.size()\n",
    "        x = x.permute(0, 2, 1)\n",
    "\n",
    "        # First LSTM layer\n",
    "        x, _ = self.lstm1(x)\n",
    "\n",
    "        # Second LSTM layer\n",
    "        x, _ = self.lstm2(x)\n",
    "        \n",
    "        # Attention layer\n",
    "        att_weights = F.softmax(self.attention(x), dim=1)\n",
    "        x = torch.sum(att_weights * x, dim=1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader: 1/268 - 1715423508.77s\n",
      "Dataloader: 2/268 - 22.89s\n",
      "Dataloader: 3/268 - 18.07s\n",
      "Dataloader: 4/268 - 19.11s\n",
      "Dataloader: 5/268 - 16.78s\n",
      "Dataloader: 6/268 - 16.09s\n",
      "Dataloader: 7/268 - 16.68s\n",
      "Dataloader: 8/268 - 17.88s\n",
      "Dataloader: 9/268 - 22.78s\n",
      "Dataloader: 10/268 - 18.41s\n",
      "Dataloader: 11/268 - 20.42s\n",
      "Dataloader: 12/268 - 17.21s\n",
      "Dataloader: 13/268 - 16.44s\n",
      "Dataloader: 14/268 - 18.22s\n",
      "Dataloader: 15/268 - 18.63s\n",
      "Dataloader: 16/268 - 17.61s\n",
      "Dataloader: 17/268 - 17.4s\n",
      "Dataloader: 18/268 - 20.64s\n",
      "Dataloader: 19/268 - 16.57s\n",
      "Dataloader: 20/268 - 16.46s\n",
      "Dataloader: 21/268 - 16.82s\n",
      "Dataloader: 22/268 - 29.07s\n",
      "Dataloader: 23/268 - 20.78s\n",
      "Dataloader: 24/268 - 17.36s\n",
      "Dataloader: 25/268 - 16.31s\n",
      "Dataloader: 26/268 - 16.51s\n",
      "Dataloader: 27/268 - 16.1s\n",
      "Dataloader: 28/268 - 16.46s\n",
      "Dataloader: 29/268 - 16.21s\n",
      "Dataloader: 30/268 - 16.45s\n",
      "Dataloader: 31/268 - 16.09s\n",
      "Dataloader: 32/268 - 16.62s\n",
      "Dataloader: 33/268 - 23.9s\n",
      "Dataloader: 34/268 - 29.64s\n",
      "Dataloader: 35/268 - 19.05s\n",
      "Dataloader: 36/268 - 14.69s\n",
      "Dataloader: 37/268 - 29.74s\n",
      "Dataloader: 38/268 - 45.82s\n",
      "Dataloader: 39/268 - 14.92s\n",
      "Dataloader: 40/268 - 14.73s\n",
      "Dataloader: 41/268 - 460.88s\n",
      "Dataloader: 42/268 - 16.85s\n",
      "Dataloader: 43/268 - 15.73s\n",
      "Dataloader: 44/268 - 20.26s\n",
      "Dataloader: 45/268 - 16.11s\n",
      "Dataloader: 46/268 - 16.24s\n",
      "Dataloader: 47/268 - 15.77s\n",
      "Dataloader: 48/268 - 15.66s\n",
      "Dataloader: 49/268 - 16.11s\n",
      "Dataloader: 50/268 - 16.91s\n",
      "Dataloader: 51/268 - 16.4s\n",
      "Dataloader: 52/268 - 17.55s\n",
      "Dataloader: 53/268 - 15.38s\n",
      "Dataloader: 54/268 - 13.83s\n",
      "Dataloader: 55/268 - 14.37s\n",
      "Dataloader: 56/268 - 14.1s\n",
      "Dataloader: 57/268 - 14.07s\n",
      "Dataloader: 58/268 - 14.94s\n",
      "Dataloader: 59/268 - 13.52s\n",
      "Dataloader: 60/268 - 14.13s\n",
      "Dataloader: 61/268 - 13.99s\n",
      "Dataloader: 62/268 - 14.26s\n",
      "Dataloader: 63/268 - 13.98s\n",
      "Dataloader: 64/268 - 13.83s\n",
      "Dataloader: 65/268 - 13.78s\n",
      "Dataloader: 66/268 - 13.34s\n",
      "Dataloader: 67/268 - 14.52s\n",
      "Dataloader: 68/268 - 14.17s\n",
      "Dataloader: 69/268 - 13.53s\n",
      "Dataloader: 70/268 - 14.19s\n",
      "Dataloader: 71/268 - 14.46s\n",
      "Dataloader: 72/268 - 14.19s\n",
      "Dataloader: 73/268 - 13.42s\n",
      "Dataloader: 74/268 - 13.53s\n",
      "Dataloader: 75/268 - 14.75s\n",
      "Dataloader: 76/268 - 16.26s\n",
      "Dataloader: 77/268 - 15.98s\n",
      "Dataloader: 78/268 - 16.4s\n",
      "Dataloader: 79/268 - 16.77s\n",
      "Dataloader: 80/268 - 16.8s\n",
      "Dataloader: 81/268 - 16.49s\n",
      "Dataloader: 82/268 - 16.25s\n",
      "Dataloader: 83/268 - 14.5s\n",
      "Dataloader: 84/268 - 15.2s\n",
      "Dataloader: 85/268 - 15.52s\n",
      "Dataloader: 86/268 - 14.18s\n",
      "Dataloader: 87/268 - 13.67s\n",
      "Dataloader: 88/268 - 13.72s\n",
      "Dataloader: 89/268 - 15.39s\n",
      "Dataloader: 90/268 - 14.24s\n",
      "Dataloader: 91/268 - 14.48s\n",
      "Dataloader: 92/268 - 13.58s\n",
      "Dataloader: 93/268 - 13.66s\n",
      "Dataloader: 94/268 - 13.99s\n",
      "Dataloader: 95/268 - 13.68s\n",
      "Dataloader: 96/268 - 14.18s\n",
      "Dataloader: 97/268 - 13.95s\n",
      "Dataloader: 98/268 - 14.14s\n",
      "Dataloader: 99/268 - 14.21s\n",
      "Dataloader: 100/268 - 13.92s\n",
      "Dataloader: 101/268 - 14.12s\n",
      "Dataloader: 102/268 - 14.94s\n",
      "Dataloader: 103/268 - 15.21s\n",
      "Dataloader: 104/268 - 14.52s\n",
      "Dataloader: 105/268 - 14.43s\n",
      "Dataloader: 106/268 - 15.74s\n",
      "Dataloader: 107/268 - 16.92s\n",
      "Dataloader: 108/268 - 15.71s\n",
      "Dataloader: 109/268 - 15.33s\n",
      "Dataloader: 110/268 - 15.17s\n",
      "Dataloader: 111/268 - 14.56s\n",
      "Dataloader: 112/268 - 15.62s\n",
      "Dataloader: 113/268 - 14.13s\n",
      "Dataloader: 114/268 - 14.43s\n",
      "Dataloader: 115/268 - 13.57s\n",
      "Dataloader: 116/268 - 13.73s\n",
      "Dataloader: 117/268 - 14.49s\n",
      "Dataloader: 118/268 - 13.93s\n",
      "Dataloader: 119/268 - 13.69s\n",
      "Dataloader: 120/268 - 14.31s\n",
      "Dataloader: 121/268 - 14.56s\n",
      "Dataloader: 122/268 - 14.37s\n",
      "Dataloader: 123/268 - 15.57s\n",
      "Dataloader: 124/268 - 14.4s\n",
      "Dataloader: 125/268 - 14.36s\n",
      "Dataloader: 126/268 - 14.18s\n",
      "Dataloader: 127/268 - 13.65s\n",
      "Dataloader: 128/268 - 13.66s\n",
      "Dataloader: 129/268 - 13.65s\n",
      "Dataloader: 130/268 - 13.56s\n",
      "Dataloader: 131/268 - 13.61s\n",
      "Dataloader: 132/268 - 14.1s\n",
      "Dataloader: 133/268 - 14.16s\n",
      "Dataloader: 134/268 - 14.88s\n",
      "Dataloader: 135/268 - 16.13s\n",
      "Dataloader: 136/268 - 13.7s\n",
      "Dataloader: 137/268 - 13.77s\n",
      "Dataloader: 138/268 - 13.76s\n",
      "Dataloader: 139/268 - 13.46s\n",
      "Dataloader: 140/268 - 13.58s\n",
      "Dataloader: 141/268 - 13.74s\n",
      "Dataloader: 142/268 - 14.1s\n",
      "Dataloader: 143/268 - 14.56s\n",
      "Dataloader: 144/268 - 13.73s\n",
      "Dataloader: 145/268 - 15.15s\n",
      "Dataloader: 146/268 - 14.22s\n",
      "Dataloader: 147/268 - 15.36s\n",
      "Dataloader: 148/268 - 14.04s\n",
      "Dataloader: 149/268 - 14.22s\n",
      "Dataloader: 150/268 - 13.4s\n",
      "Dataloader: 151/268 - 13.68s\n",
      "Dataloader: 152/268 - 14.83s\n",
      "Dataloader: 153/268 - 14.31s\n",
      "Dataloader: 154/268 - 13.85s\n",
      "Dataloader: 155/268 - 13.53s\n",
      "Dataloader: 156/268 - 13.37s\n",
      "Dataloader: 157/268 - 13.67s\n",
      "Dataloader: 158/268 - 13.59s\n",
      "Dataloader: 159/268 - 13.81s\n",
      "Dataloader: 160/268 - 13.64s\n",
      "Dataloader: 161/268 - 13.64s\n",
      "Dataloader: 162/268 - 13.5s\n",
      "Dataloader: 163/268 - 13.72s\n",
      "Dataloader: 164/268 - 13.61s\n",
      "Dataloader: 165/268 - 14.16s\n",
      "Dataloader: 166/268 - 14.77s\n",
      "Dataloader: 167/268 - 13.67s\n",
      "Dataloader: 168/268 - 13.47s\n",
      "Dataloader: 169/268 - 13.54s\n",
      "Dataloader: 170/268 - 14.74s\n",
      "Dataloader: 171/268 - 13.7s\n",
      "Dataloader: 172/268 - 14.8s\n",
      "Dataloader: 173/268 - 14.89s\n",
      "Dataloader: 174/268 - 14.31s\n",
      "Dataloader: 175/268 - 15.51s\n",
      "Dataloader: 176/268 - 13.26s\n",
      "Dataloader: 177/268 - 13.42s\n",
      "Dataloader: 178/268 - 13.56s\n",
      "Dataloader: 179/268 - 13.87s\n",
      "Dataloader: 180/268 - 14.31s\n",
      "Dataloader: 181/268 - 14.95s\n",
      "Dataloader: 182/268 - 13.89s\n",
      "Dataloader: 183/268 - 13.61s\n",
      "Dataloader: 184/268 - 13.73s\n",
      "Dataloader: 185/268 - 15.35s\n",
      "Dataloader: 186/268 - 15.85s\n",
      "Dataloader: 187/268 - 14.6s\n",
      "Dataloader: 188/268 - 14.36s\n",
      "Dataloader: 189/268 - 14.04s\n",
      "Dataloader: 190/268 - 13.99s\n",
      "Dataloader: 191/268 - 14.18s\n",
      "Dataloader: 192/268 - 13.9s\n",
      "Dataloader: 193/268 - 13.7s\n",
      "Dataloader: 194/268 - 14.13s\n",
      "Dataloader: 195/268 - 13.5s\n",
      "Dataloader: 196/268 - 13.93s\n",
      "Dataloader: 197/268 - 14.44s\n",
      "Dataloader: 198/268 - 13.88s\n",
      "Dataloader: 199/268 - 13.92s\n",
      "Dataloader: 200/268 - 13.7s\n",
      "Dataloader: 201/268 - 13.96s\n",
      "Dataloader: 202/268 - 13.93s\n",
      "Dataloader: 203/268 - 14.13s\n",
      "Dataloader: 204/268 - 14.34s\n",
      "Dataloader: 205/268 - 13.87s\n",
      "Dataloader: 206/268 - 14.19s\n",
      "Dataloader: 207/268 - 14.38s\n",
      "Dataloader: 208/268 - 13.99s\n",
      "Dataloader: 209/268 - 14.85s\n",
      "Dataloader: 210/268 - 13.8s\n",
      "Dataloader: 211/268 - 13.56s\n",
      "Dataloader: 212/268 - 13.83s\n",
      "Dataloader: 213/268 - 14.22s\n",
      "Dataloader: 214/268 - 13.87s\n",
      "Dataloader: 215/268 - 13.61s\n",
      "Dataloader: 216/268 - 13.34s\n",
      "Dataloader: 217/268 - 13.55s\n",
      "Dataloader: 218/268 - 13.96s\n",
      "Dataloader: 219/268 - 13.49s\n",
      "Dataloader: 220/268 - 14.18s\n",
      "Dataloader: 221/268 - 14.36s\n",
      "Dataloader: 222/268 - 13.68s\n",
      "Dataloader: 223/268 - 13.33s\n",
      "Dataloader: 224/268 - 13.52s\n",
      "Dataloader: 225/268 - 13.44s\n",
      "Dataloader: 226/268 - 13.87s\n",
      "Dataloader: 227/268 - 13.95s\n",
      "Dataloader: 228/268 - 14.03s\n",
      "Dataloader: 229/268 - 14.25s\n",
      "Dataloader: 230/268 - 13.94s\n",
      "Dataloader: 231/268 - 16.0s\n",
      "Dataloader: 232/268 - 14.58s\n",
      "Dataloader: 233/268 - 14.27s\n",
      "Dataloader: 234/268 - 15.27s\n",
      "Dataloader: 235/268 - 13.27s\n",
      "Dataloader: 236/268 - 13.6s\n",
      "Dataloader: 237/268 - 13.06s\n",
      "Dataloader: 238/268 - 13.11s\n",
      "Dataloader: 239/268 - 13.53s\n",
      "Dataloader: 240/268 - 12.95s\n",
      "Dataloader: 241/268 - 13.17s\n",
      "Dataloader: 242/268 - 13.53s\n",
      "Dataloader: 243/268 - 13.7s\n",
      "Dataloader: 244/268 - 13.5s\n",
      "Dataloader: 245/268 - 12.99s\n",
      "Dataloader: 246/268 - 13.24s\n",
      "Dataloader: 247/268 - 13.42s\n",
      "Dataloader: 248/268 - 12.87s\n",
      "Dataloader: 249/268 - 13.02s\n",
      "Dataloader: 250/268 - 13.23s\n",
      "Dataloader: 251/268 - 13.44s\n",
      "Dataloader: 252/268 - 13.13s\n",
      "Dataloader: 253/268 - 13.95s\n",
      "Dataloader: 254/268 - 12.71s\n",
      "Dataloader: 255/268 - 15.45s\n",
      "Dataloader: 256/268 - 13.75s\n",
      "Dataloader: 257/268 - 13.41s\n",
      "Dataloader: 258/268 - 13.38s\n",
      "Dataloader: 259/268 - 14.18s\n",
      "Dataloader: 260/268 - 14.25s\n",
      "Dataloader: 261/268 - 14.03s\n",
      "Dataloader: 262/268 - 13.99s\n",
      "Dataloader: 263/268 - 13.61s\n",
      "Dataloader: 264/268 - 13.91s\n",
      "Dataloader: 265/268 - 14.51s\n",
      "Dataloader: 266/268 - 13.57s\n",
      "Dataloader: 267/268 - 13.31s\n",
      "Dataloader: 268/268 - 13.45s\n",
      "Epoch 1, Loss: 1.5773152250852158\n"
     ]
    }
   ],
   "source": [
    "input_channels = 8\n",
    "num_classes = 6  \n",
    "\n",
    "\n",
    "model = CNNLSTM(in_channels=input_channels, num_classes=num_classes)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "s = 0\n",
    "num_epochs = 1 \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        print(f\"Dataloader: {i+1}/{len(dataloader)} - {round(time.time()-s,2)}s\")\n",
    "        s = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader: 1/268 - 270.52s\n",
      "Dataloader: 2/268 - 10.83s\n",
      "Dataloader: 3/268 - 14.19s\n",
      "Dataloader: 4/268 - 13.72s\n",
      "Dataloader: 5/268 - 13.72s\n",
      "Dataloader: 6/268 - 13.81s\n",
      "Dataloader: 7/268 - 14.0s\n",
      "Dataloader: 8/268 - 14.85s\n",
      "Dataloader: 9/268 - 13.77s\n",
      "Dataloader: 10/268 - 14.09s\n",
      "Dataloader: 11/268 - 13.93s\n",
      "Dataloader: 12/268 - 13.29s\n",
      "Dataloader: 13/268 - 13.49s\n",
      "Dataloader: 14/268 - 13.27s\n",
      "Dataloader: 15/268 - 13.52s\n",
      "Dataloader: 16/268 - 13.37s\n",
      "Dataloader: 17/268 - 13.98s\n",
      "Dataloader: 18/268 - 13.39s\n",
      "Dataloader: 19/268 - 14.0s\n",
      "Dataloader: 20/268 - 13.71s\n",
      "Dataloader: 21/268 - 13.36s\n",
      "Dataloader: 22/268 - 13.46s\n",
      "Dataloader: 23/268 - 13.45s\n",
      "Dataloader: 24/268 - 13.57s\n",
      "Dataloader: 25/268 - 14.12s\n",
      "Dataloader: 26/268 - 14.46s\n",
      "Dataloader: 27/268 - 14.39s\n",
      "Dataloader: 28/268 - 15.14s\n",
      "Dataloader: 29/268 - 16.11s\n",
      "Dataloader: 30/268 - 14.25s\n",
      "Dataloader: 31/268 - 14.39s\n",
      "Dataloader: 32/268 - 13.84s\n",
      "Dataloader: 33/268 - 14.93s\n",
      "Dataloader: 34/268 - 14.53s\n",
      "Dataloader: 35/268 - 14.21s\n",
      "Dataloader: 36/268 - 14.32s\n",
      "Dataloader: 37/268 - 14.83s\n",
      "Dataloader: 38/268 - 14.4s\n",
      "Dataloader: 39/268 - 15.81s\n",
      "Dataloader: 40/268 - 14.59s\n",
      "Dataloader: 41/268 - 15.15s\n",
      "Dataloader: 42/268 - 14.09s\n",
      "Dataloader: 43/268 - 15.34s\n",
      "Dataloader: 44/268 - 14.79s\n",
      "Dataloader: 45/268 - 14.34s\n",
      "Dataloader: 46/268 - 13.05s\n",
      "Dataloader: 47/268 - 15.36s\n",
      "Dataloader: 48/268 - 14.23s\n",
      "Dataloader: 49/268 - 13.14s\n",
      "Dataloader: 50/268 - 13.61s\n",
      "Dataloader: 51/268 - 13.29s\n",
      "Dataloader: 52/268 - 13.66s\n",
      "Dataloader: 53/268 - 12.77s\n",
      "Dataloader: 54/268 - 14.52s\n",
      "Dataloader: 55/268 - 13.46s\n",
      "Dataloader: 56/268 - 12.73s\n",
      "Dataloader: 57/268 - 12.98s\n",
      "Dataloader: 58/268 - 13.1s\n",
      "Dataloader: 59/268 - 14.9s\n",
      "Dataloader: 60/268 - 12.77s\n",
      "Dataloader: 61/268 - 13.16s\n",
      "Dataloader: 62/268 - 12.88s\n",
      "Dataloader: 63/268 - 13.1s\n",
      "Dataloader: 64/268 - 12.76s\n",
      "Dataloader: 65/268 - 13.37s\n",
      "Dataloader: 66/268 - 12.95s\n",
      "Dataloader: 67/268 - 13.47s\n",
      "Dataloader: 68/268 - 15.68s\n",
      "Dataloader: 69/268 - 13.6s\n",
      "Dataloader: 70/268 - 12.75s\n",
      "Dataloader: 71/268 - 14.02s\n",
      "Dataloader: 72/268 - 12.71s\n",
      "Dataloader: 73/268 - 13.49s\n",
      "Dataloader: 74/268 - 13.68s\n",
      "Dataloader: 75/268 - 14.12s\n",
      "Dataloader: 76/268 - 13.81s\n",
      "Dataloader: 77/268 - 12.99s\n",
      "Dataloader: 78/268 - 13.48s\n",
      "Dataloader: 79/268 - 13.48s\n",
      "Dataloader: 80/268 - 13.63s\n",
      "Dataloader: 81/268 - 12.86s\n",
      "Dataloader: 82/268 - 13.08s\n",
      "Dataloader: 83/268 - 12.95s\n",
      "Dataloader: 84/268 - 12.83s\n",
      "Dataloader: 85/268 - 13.89s\n",
      "Dataloader: 86/268 - 12.67s\n",
      "Dataloader: 87/268 - 12.85s\n",
      "Dataloader: 88/268 - 12.86s\n",
      "Dataloader: 89/268 - 12.8s\n",
      "Dataloader: 90/268 - 12.81s\n",
      "Dataloader: 91/268 - 12.93s\n",
      "Dataloader: 92/268 - 13.56s\n",
      "Dataloader: 93/268 - 13.19s\n",
      "Dataloader: 94/268 - 13.53s\n",
      "Dataloader: 95/268 - 12.93s\n",
      "Dataloader: 96/268 - 12.97s\n",
      "Dataloader: 97/268 - 13.15s\n",
      "Dataloader: 98/268 - 20.67s\n",
      "Dataloader: 99/268 - 14.72s\n",
      "Dataloader: 100/268 - 13.82s\n",
      "Dataloader: 101/268 - 12.83s\n",
      "Dataloader: 102/268 - 12.89s\n",
      "Dataloader: 103/268 - 14.11s\n",
      "Dataloader: 104/268 - 13.4s\n",
      "Dataloader: 105/268 - 12.96s\n",
      "Dataloader: 106/268 - 12.95s\n",
      "Dataloader: 107/268 - 13.22s\n",
      "Dataloader: 108/268 - 14.78s\n",
      "Dataloader: 109/268 - 12.86s\n",
      "Dataloader: 110/268 - 12.96s\n",
      "Dataloader: 111/268 - 12.96s\n",
      "Dataloader: 112/268 - 12.95s\n",
      "Dataloader: 113/268 - 13.8s\n",
      "Dataloader: 114/268 - 13.43s\n",
      "Dataloader: 115/268 - 13.02s\n",
      "Dataloader: 116/268 - 13.33s\n",
      "Dataloader: 117/268 - 12.9s\n",
      "Dataloader: 118/268 - 13.38s\n",
      "Dataloader: 119/268 - 13.31s\n",
      "Dataloader: 120/268 - 13.37s\n",
      "Dataloader: 121/268 - 19.73s\n",
      "Dataloader: 122/268 - 14.19s\n",
      "Dataloader: 123/268 - 13.87s\n",
      "Dataloader: 124/268 - 13.18s\n",
      "Dataloader: 125/268 - 12.74s\n",
      "Dataloader: 126/268 - 13.32s\n",
      "Dataloader: 127/268 - 13.72s\n",
      "Dataloader: 128/268 - 16.21s\n",
      "Dataloader: 129/268 - 13.41s\n",
      "Dataloader: 130/268 - 13.66s\n",
      "Dataloader: 131/268 - 13.52s\n",
      "Dataloader: 132/268 - 13.25s\n",
      "Dataloader: 133/268 - 14.22s\n",
      "Dataloader: 134/268 - 13.08s\n",
      "Dataloader: 135/268 - 13.4s\n",
      "Dataloader: 136/268 - 13.33s\n",
      "Dataloader: 137/268 - 13.02s\n",
      "Dataloader: 138/268 - 13.62s\n",
      "Dataloader: 139/268 - 12.98s\n",
      "Dataloader: 140/268 - 15.11s\n",
      "Dataloader: 141/268 - 15.37s\n",
      "Dataloader: 142/268 - 12.98s\n",
      "Dataloader: 143/268 - 12.86s\n",
      "Dataloader: 144/268 - 13.07s\n",
      "Dataloader: 145/268 - 12.89s\n",
      "Dataloader: 146/268 - 14.16s\n",
      "Dataloader: 147/268 - 13.13s\n",
      "Dataloader: 148/268 - 12.88s\n",
      "Dataloader: 149/268 - 12.98s\n",
      "Dataloader: 150/268 - 12.89s\n",
      "Dataloader: 151/268 - 13.05s\n",
      "Dataloader: 152/268 - 12.95s\n",
      "Dataloader: 153/268 - 13.09s\n",
      "Dataloader: 154/268 - 13.08s\n",
      "Dataloader: 155/268 - 14.65s\n",
      "Dataloader: 156/268 - 14.43s\n",
      "Dataloader: 157/268 - 13.61s\n",
      "Dataloader: 158/268 - 13.22s\n",
      "Dataloader: 159/268 - 13.03s\n",
      "Dataloader: 160/268 - 13.99s\n",
      "Dataloader: 161/268 - 13.28s\n",
      "Dataloader: 162/268 - 12.93s\n",
      "Dataloader: 163/268 - 12.88s\n",
      "Dataloader: 164/268 - 12.95s\n",
      "Dataloader: 165/268 - 13.38s\n",
      "Dataloader: 166/268 - 13.61s\n",
      "Dataloader: 167/268 - 13.35s\n",
      "Dataloader: 168/268 - 14.36s\n",
      "Dataloader: 169/268 - 13.3s\n",
      "Dataloader: 170/268 - 13.47s\n",
      "Dataloader: 171/268 - 16.21s\n",
      "Dataloader: 172/268 - 14.29s\n",
      "Dataloader: 173/268 - 13.58s\n",
      "Dataloader: 174/268 - 13.73s\n",
      "Dataloader: 175/268 - 15.21s\n",
      "Dataloader: 176/268 - 13.5s\n",
      "Dataloader: 177/268 - 13.58s\n",
      "Dataloader: 178/268 - 13.27s\n",
      "Dataloader: 179/268 - 13.13s\n",
      "Dataloader: 180/268 - 13.46s\n",
      "Dataloader: 181/268 - 13.58s\n",
      "Dataloader: 182/268 - 13.95s\n",
      "Dataloader: 183/268 - 13.31s\n",
      "Dataloader: 184/268 - 13.24s\n",
      "Dataloader: 185/268 - 12.8s\n",
      "Dataloader: 186/268 - 13.17s\n",
      "Dataloader: 187/268 - 13.2s\n",
      "Dataloader: 188/268 - 13.78s\n",
      "Dataloader: 189/268 - 12.89s\n",
      "Dataloader: 190/268 - 13.45s\n",
      "Dataloader: 191/268 - 13.02s\n",
      "Dataloader: 192/268 - 13.18s\n",
      "Dataloader: 193/268 - 14.16s\n",
      "Dataloader: 194/268 - 12.97s\n",
      "Dataloader: 195/268 - 12.89s\n",
      "Dataloader: 196/268 - 13.87s\n",
      "Dataloader: 197/268 - 14.42s\n",
      "Dataloader: 198/268 - 13.04s\n",
      "Dataloader: 199/268 - 12.72s\n",
      "Dataloader: 200/268 - 13.11s\n",
      "Dataloader: 201/268 - 13.02s\n",
      "Dataloader: 202/268 - 14.33s\n",
      "Dataloader: 203/268 - 13.65s\n",
      "Dataloader: 204/268 - 14.14s\n",
      "Dataloader: 205/268 - 13.55s\n",
      "Dataloader: 206/268 - 13.3s\n",
      "Dataloader: 207/268 - 13.39s\n",
      "Dataloader: 208/268 - 14.54s\n",
      "Dataloader: 209/268 - 12.95s\n",
      "Dataloader: 210/268 - 12.86s\n",
      "Dataloader: 211/268 - 12.96s\n",
      "Dataloader: 212/268 - 14.47s\n",
      "Dataloader: 213/268 - 13.24s\n",
      "Dataloader: 214/268 - 13.09s\n",
      "Dataloader: 215/268 - 13.06s\n",
      "Dataloader: 216/268 - 13.4s\n",
      "Dataloader: 217/268 - 13.24s\n",
      "Dataloader: 218/268 - 13.56s\n",
      "Dataloader: 219/268 - 16.82s\n",
      "Dataloader: 220/268 - 14.68s\n",
      "Dataloader: 221/268 - 13.26s\n",
      "Dataloader: 222/268 - 13.12s\n",
      "Dataloader: 223/268 - 13.5s\n",
      "Dataloader: 224/268 - 13.07s\n",
      "Dataloader: 225/268 - 14.54s\n",
      "Dataloader: 226/268 - 13.22s\n",
      "Dataloader: 227/268 - 13.22s\n",
      "Dataloader: 228/268 - 13.35s\n",
      "Dataloader: 229/268 - 14.35s\n",
      "Dataloader: 230/268 - 13.0s\n",
      "Dataloader: 231/268 - 13.28s\n",
      "Dataloader: 232/268 - 13.18s\n",
      "Dataloader: 233/268 - 14.91s\n",
      "Dataloader: 234/268 - 14.18s\n",
      "Dataloader: 235/268 - 14.44s\n",
      "Dataloader: 236/268 - 15.53s\n",
      "Dataloader: 237/268 - 14.93s\n",
      "Dataloader: 238/268 - 13.06s\n",
      "Dataloader: 239/268 - 12.89s\n",
      "Dataloader: 240/268 - 13.9s\n",
      "Dataloader: 241/268 - 14.71s\n",
      "Dataloader: 242/268 - 14.97s\n",
      "Dataloader: 243/268 - 14.58s\n",
      "Dataloader: 244/268 - 13.15s\n",
      "Dataloader: 245/268 - 13.57s\n",
      "Dataloader: 246/268 - 13.37s\n",
      "Dataloader: 247/268 - 14.84s\n",
      "Dataloader: 248/268 - 13.48s\n",
      "Dataloader: 249/268 - 12.99s\n",
      "Dataloader: 250/268 - 13.23s\n",
      "Dataloader: 251/268 - 12.98s\n",
      "Dataloader: 252/268 - 14.0s\n",
      "Dataloader: 253/268 - 14.84s\n",
      "Dataloader: 254/268 - 13.35s\n",
      "Dataloader: 255/268 - 13.2s\n",
      "Dataloader: 256/268 - 13.12s\n",
      "Dataloader: 257/268 - 13.32s\n",
      "Dataloader: 258/268 - 14.3s\n",
      "Dataloader: 259/268 - 12.95s\n",
      "Dataloader: 260/268 - 13.13s\n",
      "Dataloader: 261/268 - 13.04s\n",
      "Dataloader: 262/268 - 13.27s\n",
      "Dataloader: 263/268 - 13.44s\n",
      "Dataloader: 264/268 - 13.66s\n",
      "Dataloader: 265/268 - 12.93s\n",
      "Dataloader: 266/268 - 13.75s\n",
      "Dataloader: 267/268 - 13.07s\n",
      "Dataloader: 268/268 - 12.78s\n",
      "Epoch 1, Loss: 1.5249786074481793\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1 \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        print(f\"Dataloader: {i+1}/{len(dataloader)} - {round(time.time()-s,2)}s\")\n",
    "        s = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '3_epoch.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.08623526 0.16573855 0.06893624 0.07671241 0.12124654 0.48113102]]\n"
     ]
    }
   ],
   "source": [
    "test_path = 'test.csv'\n",
    "TEST_EEG_PATH = 'test_eegs'\n",
    "\n",
    "class TestEEGDataset(Dataset):\n",
    "    def __init__(self, csv_file, eeg_path):\n",
    "        self.csv = pd.read_csv(csv_file)  # Load the CSV file\n",
    "        self.eeg_path = eeg_path\n",
    "        self.sos = self.butter_bandpass_filter_init()  # Initialize the Butterworth filter parameters\n",
    "        self.FEATS = ['Fp1','T3','C3','O1','Fp2','C4','T4','O2']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.csv)\n",
    "    \n",
    "    def butter_bandpass_filter_init(self):\n",
    "        lowcut = 0.5  # Set the low-frequency cutoff for bandpass filtering\n",
    "        highcut = 45.0  # Set the high-frequency cutoff for bandpass filtering\n",
    "        fs = 200.0  # Sampling frequency\n",
    "        order = 5  # Filter order\n",
    "\n",
    "        nyq = 0.5 * fs\n",
    "        low = lowcut / nyq\n",
    "        high = highcut / nyq\n",
    "        sos = butter(order, [low, high], analog=False, btype='band', output='sos')  # Create second-order sections for the Butterworth filter\n",
    "        return sos\n",
    "\n",
    "    def butter_bandpass_filter(self, data):\n",
    "        y = sosfilt(self.sos, data)\n",
    "        return y\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        eeg_id = self.csv.loc[idx, 'eeg_id']\n",
    "        eeg_file_path = \"/Users/chloenguyen/Downloads/eeg_data/test_eegs/3911565283.parquet\"  # Build the EEG data file path\n",
    "        eeg_data = pd.read_parquet(eeg_file_path)[self.FEATS].values  # Load EEG data from Parquet file\n",
    "\n",
    "        eeg_data = self.butter_bandpass_filter(eeg_data)  # Apply filtering to the data\n",
    "        eeg_data = torch.tensor(eeg_data, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "         \n",
    "        # Select 10,000 data points from the middle\n",
    "        mid_index = eeg_data.shape[0] // 2\n",
    "        start_index = mid_index - 5000  # Offset 5000 data points to the left from the middle\n",
    "        end_index = mid_index + 5000  # Offset 5000 data points to the right from the middle\n",
    "        eeg_data = eeg_data[start_index:end_index]\n",
    "        # Swap dimensions\n",
    "        eeg_data = torch.transpose(eeg_data, 0, 1)\n",
    "        \n",
    "        return eeg_data\n",
    "\n",
    "\n",
    "testdataset = TestEEGDataset(test_path, TEST_EEG_PATH)\n",
    "\n",
    "\n",
    "test_dataloader = DataLoader(testdataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in test_dataloader:\n",
    "        outputs = model(inputs)\n",
    "      \n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predictions.append(probabilities.cpu().numpy())\n",
    "\n",
    "\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote\n",
      "0      0.086235  0.165739  0.068936   0.076712   0.121247    0.481131\n"
     ]
    }
   ],
   "source": [
    "columns = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "results_df = pd.DataFrame(predictions, columns=columns)\n",
    "\n",
    "#  DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id\n",
       "0  3911565283"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(test_path)\n",
    "sub = pd.DataFrame({'eeg_id':test_data.eeg_id.values})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
