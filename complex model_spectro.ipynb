{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramisa7/Team_EEG/blob/main/Milestone1_Data_Science_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb0ZiNWbCgft"
      },
      "source": [
        "# 1. Initial Data Analysis\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1r95B7L4YQ_",
        "outputId": "ab1f3763-bd6e-4d80-a636-13f2fd7665fb"
      },
      "outputs": [],
      "source": [
        "# %pip install google-colab\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "G7Eneza74wL4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: seaborn in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from seaborn) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.25 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from seaborn) (2.0.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from seaborn) (3.7.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.1)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pyarrow in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pyarrow) (1.24.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: fastparquet in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (2024.2.0)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from fastparquet) (2.0.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from fastparquet) (1.24.3)\n",
            "Requirement already satisfied: cramjam>=2.3 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from fastparquet) (2.8.3)\n",
            "Requirement already satisfied: fsspec in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from fastparquet) (2024.3.1)\n",
            "Requirement already satisfied: packaging in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from fastparquet) (23.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: keras_cv in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (0.9.0)\n",
            "Requirement already satisfied: packaging in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras_cv) (23.2)\n",
            "Requirement already satisfied: absl-py in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras_cv) (2.1.0)\n",
            "Requirement already satisfied: regex in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras_cv) (2022.7.9)\n",
            "Requirement already satisfied: tensorflow-datasets in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras_cv) (4.9.4)\n",
            "Requirement already satisfied: keras-core in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras_cv) (0.1.7)\n",
            "Requirement already satisfied: kagglehub in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras_cv) (0.2.5)\n",
            "Requirement already satisfied: requests in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from kagglehub->keras_cv) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from kagglehub->keras_cv) (4.65.0)\n",
            "Requirement already satisfied: numpy in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras-core->keras_cv) (1.24.3)\n",
            "Requirement already satisfied: rich in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras-core->keras_cv) (13.7.1)\n",
            "Requirement already satisfied: namex in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras-core->keras_cv) (0.0.8)\n",
            "Requirement already satisfied: h5py in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras-core->keras_cv) (3.11.0)\n",
            "Requirement already satisfied: dm-tree in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from keras-core->keras_cv) (0.1.8)\n",
            "Requirement already satisfied: click in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (8.0.4)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (1.8.0)\n",
            "Requirement already satisfied: promise in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (4.25.3)\n",
            "Requirement already satisfied: psutil in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (5.9.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (1.15.0)\n",
            "Requirement already satisfied: termcolor in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
            "Requirement already satisfied: toml in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
            "Requirement already satisfied: wrapt in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
            "Requirement already satisfied: fsspec in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2024.3.1)\n",
            "Requirement already satisfied: importlib_resources in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.4.0)\n",
            "Requirement already satisfied: typing_extensions in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.10.0)\n",
            "Requirement already satisfied: zipp in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from requests->kagglehub->keras_cv) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from requests->kagglehub->keras_cv) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from requests->kagglehub->keras_cv) (2023.11.17)\n",
            "Requirement already satisfied: six in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from rich->keras-core->keras_cv) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from rich->keras-core->keras_cv) (2.15.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.63.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/rubysapkota/anaconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "%pip install matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%pip install seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "%pip install pyarrow\n",
        "%pip install fastparquet\n",
        "\n",
        "import os\n",
        "\n",
        "%pip install keras_cv\n",
        "import keras_cv\n",
        "import keras\n",
        "from keras import ops\n",
        "import tensorflow as tf\n",
        "\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import joblib\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48jwISL194H1"
      },
      "source": [
        "In the initial data analysis phase, we start by loading the dataset and examining its structure, summary statistics, and distribution of values. This helps us gain insights into the data and understand its characteristics before proceeding with further analysis or modeling. We also visualize the distribution of certain features in the dataset using histograms, bar plots, or box plots. This helps us understand the distribution of values and identify any patterns or outliers in the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "oyasNSiGChne",
        "outputId": "4abc05b4-e6ad-4b85-d7cb-7c72c6694039"
      },
      "outputs": [],
      "source": [
        "\n",
        "# train_path = r\"train.csv\"\n",
        "# train_data = pd.read_csv(train_path)\n",
        "# train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCvylawL4hv7",
        "outputId": "39d7a43c-97a5-4779-9fa5-4c0802da2d8a"
      },
      "outputs": [],
      "source": [
        "# print('Train shape:', train_data.shape )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXO55dX9_CYB",
        "outputId": "67759f9b-6663-4ac1-bbca-fc0df02c009e"
      },
      "outputs": [],
      "source": [
        "# targets = train_data.columns[-6:]\n",
        "# print('Targets', list(targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Summary statistics for numerical columns in train.csv\n",
        "# print(\"\\nSummary Statistics - Training Data:\")\n",
        "# (train_data.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPQDvfYZ2Ox9",
        "outputId": "1360812a-3eca-4104-9d9b-98f8d10f0900"
      },
      "outputs": [],
      "source": [
        "# #count missing values\n",
        "# missing_values = train_data.isnull().sum()\n",
        "# missing_values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WdXaqoiR6kNv"
      },
      "outputs": [],
      "source": [
        "# duplicate_rows = train_data[train_data.duplicated()].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euGI7Stw6zLW"
      },
      "source": [
        "There is no missing/duplicate data.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Skm-Y4ArCZtY"
      },
      "outputs": [],
      "source": [
        "# # Distribution of classes in train.csv\n",
        "# class_distribution = train_data[targets].sum()\n",
        "\n",
        "# # convert vote to probability\n",
        "# train_data[targets] /= train_data[targets].sum(axis=1).values[:, None]\n",
        "# train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Visualize distribution of spectrogram_label_offset_seconds in train.csv\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# sns.histplot(train_data['spectrogram_label_offset_seconds'], bins=30, kde=True)\n",
        "# plt.title('Distribution of Spectrogram Label Offset Seconds in Training Data')\n",
        "# plt.xlabel('Spectrogram Label Offset Seconds')\n",
        "# plt.ylabel('Count')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Plot the distribution of classes\n",
        "# plt.figure(figsize=(8, 4))\n",
        "# sns.barplot(x=class_distribution.index, y=class_distribution.values)\n",
        "# plt.title('Distribution of Classes in Training Data')\n",
        "# plt.xlabel('Brain Activity Classes')\n",
        "# plt.ylabel('Number of Votes')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Relationship between classes and patient_id in train.csv\n",
        "# plt.figure(figsize=(12, 8))\n",
        "# sns.boxplot(x='patient_id', y='seizure_vote', data=train_data)\n",
        "# plt.title('Relationship between Seizure Votes and Patient ID in Training Data')\n",
        "# plt.xlabel('Patient ID')\n",
        "# plt.ylabel('Seizure Votes')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vu7jTfQ88HjI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import os  # Import the os module for file path manipulation\n",
        "\n",
        "# # raw data visualization:\n",
        "# spectrogram_id = 353733\t\n",
        "# subsample_id = 0\n",
        "\n",
        "# # Construct the file path\n",
        "# base_dir = \"train_spectrograms\"  # Specify the base directory\n",
        "# spect_filename = os.path.join(base_dir, f\"{spectrogram_id}.parquet\")  \n",
        "\n",
        "\n",
        "# # try:\n",
        "# raw_spect_data = pd.read_parquet(spect_filename)\n",
        "# # Plot each electrode channel\n",
        "# for column in raw_spect_data.columns:\n",
        "#     fig, ax = plt.subplots(figsize=(10, 6))  # Create a new figure and axis for each plot\n",
        "#     ax.plot(raw_spect_data.index, raw_spect_data[column], label=column)\n",
        "#     ax.set_title(\"Raw Spectrogram Signal - \" + column)\n",
        "#     ax.set_xlabel(\"Time\")\n",
        "#     ax.set_ylabel(\"Voltage\")\n",
        "#     ax.legend()\n",
        "#     plt.show()\n",
        "\n",
        "\n",
        "# print(\"Raw data visualization successful.\")\n",
        "# # except FileNotFoundError:\n",
        "# #     print(f\"File {eeg_filename} not found.\")\n",
        "# # except Exception as e:\n",
        "# #     print(f\"An error occurred: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # extractdata from parquet file \n",
        "\n",
        "# import pyarrow.parquet as pq\n",
        "# import os\n",
        "\n",
        "# # Load the parquet file\n",
        "# spectrogram_id = 353733\t\n",
        "# base_dir = \"train_spectrograms\"  \n",
        "# spect_filename = os.path.join(base_dir, f\"{spectrogram_id}.parquet\")\n",
        "# spect_data = pq.read_table(spect_filename).to_pandas()\n",
        "\n",
        "# # Display the first  row of the data\n",
        "# print(spect_data.head(5))\n",
        "\n",
        "# #check the shape \n",
        "# print(spect_data.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# spect_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndO78ugFDnBy"
      },
      "source": [
        "# 4. Complex Model (SPECTROGRAM): \n",
        "\n",
        "[ WORK ON PROGRESS]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from scipy.stats import skew, kurtosis\n",
        "\n",
        "# # Calculate mean, median, variance, skewness, and kurtosis for each channel\n",
        "# statistical_features = pd.DataFrame({\n",
        "#     'Channel': spect_data.columns,\n",
        "#     'Mean': spect_data.mean(),\n",
        "#     'Median': spect_data.median(),\n",
        "#     'Variance': spect_data.var(),\n",
        "#     'Skewness': spect_data.apply(skew),\n",
        "#     'Kurtosis': spect_data.apply(kurtosis)\n",
        "# })\n",
        "\n",
        "# # Display the statistical features\n",
        "# statistical_features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CFG:\n",
        "    verbose = 1  # Verbosity\n",
        "    seed = 42  # Random seed\n",
        "    preset = \"efficientnetv2_b2_imagenet\"  # Name of pretrained classifier\n",
        "    image_size = [400, 300]  # Input image size\n",
        "    epochs = 13 # Training epochs\n",
        "    batch_size = 64  # Batch size\n",
        "    lr_mode = \"cos\" # LR scheduler mode from one of \"cos\", \"step\", \"exp\"\n",
        "    drop_remainder = True  # Drop incomplete batches\n",
        "    num_classes = 6 # Number of classes in the dataset\n",
        "    fold = 0 # Which fold to set as validation data\n",
        "    class_names = ['Seizure', 'LPD', 'GPD', 'LRDA','GRDA', 'Other']\n",
        "    label2name = dict(enumerate(class_names))\n",
        "    name2label = {v:k for k, v in label2name.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Sets value for random seed to produce similar result in each run.\n",
        "\n",
        "keras.utils.set_random_seed(CFG.seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Meta Data: \n",
        "\n",
        "# # Train + Valid\n",
        "# df = pd.read_csv('train.csv')\n",
        "# df['eeg_path'] = f'train_eegs/'+df['eeg_id'].astype(str)+'.parquet'\n",
        "# df['spect_path'] = f'train_spectrograms/'+df['spectrogram_id'].astype(str)+'.parquet'\n",
        "# df['class_name'] = df.expert_consensus.copy()\n",
        "# df['class_label'] = df.expert_consensus.map(CFG.name2label)\n",
        "# # display(df.tail(5))\n",
        "# # display(df.head(5))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # Test\n",
        "# test_df =  pd.read_csv('test.csv')\n",
        "# test_df['eeg_path'] = f'test_eegs/'+test_df['eeg_id'].astype(str)+'.parquet'\n",
        "# test_df['spec_path'] = f'test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.parquet'\n",
        "# # display(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TRAIN, TEST AND VALID SPLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set shape: (96120, 19)\n",
            "Test set shape: (10680, 19)\n"
          ]
        }
      ],
      "source": [
        "# Load the data\n",
        "\n",
        "#df is for train and valid both\n",
        "df = pd.read_csv('train.csv')\n",
        "df['eeg_path'] = f'train_eegs/'+df['eeg_id'].astype(str)+'.parquet'\n",
        "df['spect_path'] = f'train_spectrograms/'+df['spectrogram_id'].astype(str)+'.parquet'\n",
        "df['class_name'] = df.expert_consensus.copy()\n",
        "df['class_label'] = df.expert_consensus.map(CFG.name2label)\n",
        "\n",
        "# Split the data into a training set and a test set using an 90-10 split\n",
        "df, test_df = train_test_split(df, test_size=0.1, random_state=CFG.seed, stratify=df['class_label'])\n",
        "\n",
        "\n",
        "\n",
        "# Give me the shape of the training, validation, and test sets\n",
        "print(f\"Training set shape: {df.shape}\")\n",
        "print(f\"Test set shape: {test_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bbd67299ae324f868c2729d893ea019c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10878 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6f674c107ff34260ad11805ba46f3be5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4698 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# turn parquet files into numpy arrays for faster loading \n",
        "# Define a function to process a single spectrogram_id\n",
        "def process_spec(spectrogram_id, split=\"train_\"):\n",
        "    spect_path = f\"{split}spectrograms/{spectrogram_id}.parquet\"\n",
        "    spect = pd.read_parquet(spect_path)\n",
        "    spect = spect.fillna(0).values[:, 1:].T\n",
        "    spect = spect.astype(\"float32\")\n",
        "    np.save(f\"{split}spectrograms/{spectrogram_id}.npy\", spect)\n",
        "\n",
        "# Get unique spec_ids of train+valid data\n",
        "spectrogram_ids = df[\"spectrogram_id\"].unique()\n",
        "\n",
        "# Parallelize the processing using joblib for training+validating data\n",
        "_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n",
        "    joblib.delayed(process_spec)(spec_id, \"train_\")\n",
        "    for spec_id in tqdm(spectrogram_ids, total=len(spectrogram_ids))\n",
        ")\n",
        "\n",
        "# Get unique spec_ids of test data\n",
        "test_spec_ids = test_df[\"spectrogram_id\"].unique()\n",
        "\n",
        "# Parallelize the processing using joblib for test data\n",
        "_ = joblib.Parallel(n_jobs=-1, backend=\"loky\")(\n",
        "    joblib.delayed(process_spec)(spec_id, \"train_\")\n",
        "    for spec_id in tqdm(test_spec_ids, total=len(test_spec_ids))\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This below block of code is used to process spectrogram data in parallel for both training and testing datasets. It first retrieves the unique spectrogram IDs from the training data. Then, it uses the joblib library to parallelize the processing of these spectrograms. The 'process_spec' function is applied to each spectrogram ID. This function is called with joblib.delayed, which means the function calls are executed in parallel, not immediately. A progress bar is created for this operation using tqdm, with the total number of iterations set to the number of unique spectrogram IDs. The results of the parallel computation are not stored, indicating that the 'process_spec' function likely performs an operation such as saving the processed spectrograms to disk. The same steps are then repeated for the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10878 4698\n"
          ]
        }
      ],
      "source": [
        "print(len(spectrogram_ids), len(test_spec_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(spectrogram_ids)\n",
        "#print (test_spec_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for spectrogram_id in spectrogram_ids:\n",
        "#     process_spec(spectrogram_id, split=\"train_\")\n",
        "     \n",
        "#for spectrogram_id in test_spec_ids:\n",
        "#     process_spec(spectrogram_id, split=\"train_\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# #load the npy files\n",
        "# spect = np.load('train_spectrograms/353733.npy')\n",
        "# print(spect.shape)\n",
        "\n",
        "# # show the first 5 rows of the data\n",
        "# print(spect[:10])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eeg_id</th>\n",
              "      <th>eeg_sub_id</th>\n",
              "      <th>eeg_label_offset_seconds</th>\n",
              "      <th>spectrogram_id</th>\n",
              "      <th>spectrogram_sub_id</th>\n",
              "      <th>spectrogram_label_offset_seconds</th>\n",
              "      <th>label_id</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>expert_consensus</th>\n",
              "      <th>seizure_vote</th>\n",
              "      <th>lpd_vote</th>\n",
              "      <th>gpd_vote</th>\n",
              "      <th>lrda_vote</th>\n",
              "      <th>grda_vote</th>\n",
              "      <th>other_vote</th>\n",
              "      <th>eeg_path</th>\n",
              "      <th>spect_path</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_label</th>\n",
              "      <th>spect2_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>69187</th>\n",
              "      <td>2259539799</td>\n",
              "      <td>153</td>\n",
              "      <td>694.0</td>\n",
              "      <td>1391458063</td>\n",
              "      <td>153</td>\n",
              "      <td>694.0</td>\n",
              "      <td>531396712</td>\n",
              "      <td>2641</td>\n",
              "      <td>GPD</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/2259539799.parquet</td>\n",
              "      <td>train_spectrograms/1391458063.parquet</td>\n",
              "      <td>GPD</td>\n",
              "      <td>2</td>\n",
              "      <td>train_spectrograms/1391458063.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40812</th>\n",
              "      <td>1516493459</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>785385791</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2620430346</td>\n",
              "      <td>62197</td>\n",
              "      <td>LRDA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/1516493459.parquet</td>\n",
              "      <td>train_spectrograms/785385791.parquet</td>\n",
              "      <td>LRDA</td>\n",
              "      <td>3</td>\n",
              "      <td>train_spectrograms/785385791.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33867</th>\n",
              "      <td>2009915165</td>\n",
              "      <td>18</td>\n",
              "      <td>90.0</td>\n",
              "      <td>668167696</td>\n",
              "      <td>18</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1080254207</td>\n",
              "      <td>53636</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/2009915165.parquet</td>\n",
              "      <td>train_spectrograms/668167696.parquet</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>0</td>\n",
              "      <td>train_spectrograms/668167696.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5039</th>\n",
              "      <td>810249434</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>82847957</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>265802662</td>\n",
              "      <td>44246</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>train_eegs/810249434.parquet</td>\n",
              "      <td>train_spectrograms/82847957.parquet</td>\n",
              "      <td>Other</td>\n",
              "      <td>5</td>\n",
              "      <td>train_spectrograms/82847957.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74926</th>\n",
              "      <td>3338940223</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1498477269</td>\n",
              "      <td>2</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2762737698</td>\n",
              "      <td>34153</td>\n",
              "      <td>GPD</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>train_eegs/3338940223.parquet</td>\n",
              "      <td>train_spectrograms/1498477269.parquet</td>\n",
              "      <td>GPD</td>\n",
              "      <td>2</td>\n",
              "      <td>train_spectrograms/1498477269.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16244</th>\n",
              "      <td>3941153433</td>\n",
              "      <td>5</td>\n",
              "      <td>100.0</td>\n",
              "      <td>322284022</td>\n",
              "      <td>5</td>\n",
              "      <td>100.0</td>\n",
              "      <td>3165798648</td>\n",
              "      <td>4814</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/3941153433.parquet</td>\n",
              "      <td>train_spectrograms/322284022.parquet</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>0</td>\n",
              "      <td>train_spectrograms/322284022.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2454</th>\n",
              "      <td>1470287332</td>\n",
              "      <td>11</td>\n",
              "      <td>48.0</td>\n",
              "      <td>37007296</td>\n",
              "      <td>11</td>\n",
              "      <td>48.0</td>\n",
              "      <td>708989365</td>\n",
              "      <td>2338</td>\n",
              "      <td>GPD</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/1470287332.parquet</td>\n",
              "      <td>train_spectrograms/37007296.parquet</td>\n",
              "      <td>GPD</td>\n",
              "      <td>2</td>\n",
              "      <td>train_spectrograms/37007296.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79821</th>\n",
              "      <td>2789122958</td>\n",
              "      <td>4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>1616768321</td>\n",
              "      <td>4</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4249349688</td>\n",
              "      <td>38387</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>train_eegs/2789122958.parquet</td>\n",
              "      <td>train_spectrograms/1616768321.parquet</td>\n",
              "      <td>Other</td>\n",
              "      <td>5</td>\n",
              "      <td>train_spectrograms/1616768321.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40158</th>\n",
              "      <td>3832216758</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>766908178</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1801826023</td>\n",
              "      <td>2573</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>train_eegs/3832216758.parquet</td>\n",
              "      <td>train_spectrograms/766908178.parquet</td>\n",
              "      <td>Other</td>\n",
              "      <td>5</td>\n",
              "      <td>train_spectrograms/766908178.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>3403533082</td>\n",
              "      <td>107</td>\n",
              "      <td>274.0</td>\n",
              "      <td>15071739</td>\n",
              "      <td>107</td>\n",
              "      <td>274.0</td>\n",
              "      <td>2324599159</td>\n",
              "      <td>26349</td>\n",
              "      <td>LRDA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/3403533082.parquet</td>\n",
              "      <td>train_spectrograms/15071739.parquet</td>\n",
              "      <td>LRDA</td>\n",
              "      <td>3</td>\n",
              "      <td>train_spectrograms/15071739.npy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10680 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
              "69187  2259539799         153                     694.0      1391458063   \n",
              "40812  1516493459           1                       2.0       785385791   \n",
              "33867  2009915165          18                      90.0       668167696   \n",
              "5039    810249434           0                       0.0        82847957   \n",
              "74926  3338940223           2                       4.0      1498477269   \n",
              "...           ...         ...                       ...             ...   \n",
              "16244  3941153433           5                     100.0       322284022   \n",
              "2454   1470287332          11                      48.0        37007296   \n",
              "79821  2789122958           4                      30.0      1616768321   \n",
              "40158  3832216758           1                       2.0       766908178   \n",
              "1258   3403533082         107                     274.0        15071739   \n",
              "\n",
              "       spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
              "69187                 153                             694.0   531396712   \n",
              "40812                   1                               2.0  2620430346   \n",
              "33867                  18                              90.0  1080254207   \n",
              "5039                    0                               0.0   265802662   \n",
              "74926                   2                               4.0  2762737698   \n",
              "...                   ...                               ...         ...   \n",
              "16244                   5                             100.0  3165798648   \n",
              "2454                   11                              48.0   708989365   \n",
              "79821                   4                              30.0  4249349688   \n",
              "40158                   1                               2.0  1801826023   \n",
              "1258                  107                             274.0  2324599159   \n",
              "\n",
              "       patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n",
              "69187        2641              GPD             5         0        10   \n",
              "40812       62197             LRDA             0         0         0   \n",
              "33867       53636          Seizure             3         0         0   \n",
              "5039        44246            Other             0         0         0   \n",
              "74926       34153              GPD             0         0         7   \n",
              "...           ...              ...           ...       ...       ...   \n",
              "16244        4814          Seizure             3         0         0   \n",
              "2454         2338              GPD             0         0         3   \n",
              "79821       38387            Other             0         0         4   \n",
              "40158        2573            Other             0         0         0   \n",
              "1258        26349             LRDA             0         0         0   \n",
              "\n",
              "       lrda_vote  grda_vote  other_vote                       eeg_path  \\\n",
              "69187          0          0           0  train_eegs/2259539799.parquet   \n",
              "40812          3          0           0  train_eegs/1516493459.parquet   \n",
              "33867          0          0           0  train_eegs/2009915165.parquet   \n",
              "5039           0          0           1   train_eegs/810249434.parquet   \n",
              "74926          0          3           3  train_eegs/3338940223.parquet   \n",
              "...          ...        ...         ...                            ...   \n",
              "16244          0          0           0  train_eegs/3941153433.parquet   \n",
              "2454           0          0           0  train_eegs/1470287332.parquet   \n",
              "79821          0          2           6  train_eegs/2789122958.parquet   \n",
              "40158          0          0           3  train_eegs/3832216758.parquet   \n",
              "1258           3          0           0  train_eegs/3403533082.parquet   \n",
              "\n",
              "                                  spect_path class_name  class_label  \\\n",
              "69187  train_spectrograms/1391458063.parquet        GPD            2   \n",
              "40812   train_spectrograms/785385791.parquet       LRDA            3   \n",
              "33867   train_spectrograms/668167696.parquet    Seizure            0   \n",
              "5039     train_spectrograms/82847957.parquet      Other            5   \n",
              "74926  train_spectrograms/1498477269.parquet        GPD            2   \n",
              "...                                      ...        ...          ...   \n",
              "16244   train_spectrograms/322284022.parquet    Seizure            0   \n",
              "2454     train_spectrograms/37007296.parquet        GPD            2   \n",
              "79821  train_spectrograms/1616768321.parquet      Other            5   \n",
              "40158   train_spectrograms/766908178.parquet      Other            5   \n",
              "1258     train_spectrograms/15071739.parquet       LRDA            3   \n",
              "\n",
              "                             spect2_path  \n",
              "69187  train_spectrograms/1391458063.npy  \n",
              "40812   train_spectrograms/785385791.npy  \n",
              "33867   train_spectrograms/668167696.npy  \n",
              "5039     train_spectrograms/82847957.npy  \n",
              "74926  train_spectrograms/1498477269.npy  \n",
              "...                                  ...  \n",
              "16244   train_spectrograms/322284022.npy  \n",
              "2454     train_spectrograms/37007296.npy  \n",
              "79821  train_spectrograms/1616768321.npy  \n",
              "40158   train_spectrograms/766908178.npy  \n",
              "1258     train_spectrograms/15071739.npy  \n",
              "\n",
              "[10680 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eeg_id</th>\n",
              "      <th>eeg_sub_id</th>\n",
              "      <th>eeg_label_offset_seconds</th>\n",
              "      <th>spectrogram_id</th>\n",
              "      <th>spectrogram_sub_id</th>\n",
              "      <th>spectrogram_label_offset_seconds</th>\n",
              "      <th>label_id</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>expert_consensus</th>\n",
              "      <th>seizure_vote</th>\n",
              "      <th>lpd_vote</th>\n",
              "      <th>gpd_vote</th>\n",
              "      <th>lrda_vote</th>\n",
              "      <th>grda_vote</th>\n",
              "      <th>other_vote</th>\n",
              "      <th>eeg_path</th>\n",
              "      <th>spect_path</th>\n",
              "      <th>class_name</th>\n",
              "      <th>class_label</th>\n",
              "      <th>spect2_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77135</th>\n",
              "      <td>1744516630</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1554060622</td>\n",
              "      <td>2</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3671005733</td>\n",
              "      <td>5393</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/1744516630.parquet</td>\n",
              "      <td>train_spectrograms/1554060622.parquet</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>0</td>\n",
              "      <td>train_spectrograms/1554060622.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89814</th>\n",
              "      <td>3288991214</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1836830050</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2340601286</td>\n",
              "      <td>65378</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>train_eegs/3288991214.parquet</td>\n",
              "      <td>train_spectrograms/1836830050.parquet</td>\n",
              "      <td>Other</td>\n",
              "      <td>5</td>\n",
              "      <td>train_spectrograms/1836830050.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37810</th>\n",
              "      <td>662625553</td>\n",
              "      <td>7</td>\n",
              "      <td>68.0</td>\n",
              "      <td>744859685</td>\n",
              "      <td>7</td>\n",
              "      <td>68.0</td>\n",
              "      <td>2026803436</td>\n",
              "      <td>29192</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/662625553.parquet</td>\n",
              "      <td>train_spectrograms/744859685.parquet</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>0</td>\n",
              "      <td>train_spectrograms/744859685.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103265</th>\n",
              "      <td>1480985066</td>\n",
              "      <td>338</td>\n",
              "      <td>1450.0</td>\n",
              "      <td>2063104016</td>\n",
              "      <td>338</td>\n",
              "      <td>1450.0</td>\n",
              "      <td>2691322208</td>\n",
              "      <td>8033</td>\n",
              "      <td>GRDA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/1480985066.parquet</td>\n",
              "      <td>train_spectrograms/2063104016.parquet</td>\n",
              "      <td>GRDA</td>\n",
              "      <td>4</td>\n",
              "      <td>train_spectrograms/2063104016.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3422</th>\n",
              "      <td>2080477284</td>\n",
              "      <td>3</td>\n",
              "      <td>14.0</td>\n",
              "      <td>55011312</td>\n",
              "      <td>3</td>\n",
              "      <td>14.0</td>\n",
              "      <td>3215853517</td>\n",
              "      <td>50648</td>\n",
              "      <td>GRDA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/2080477284.parquet</td>\n",
              "      <td>train_spectrograms/55011312.parquet</td>\n",
              "      <td>GRDA</td>\n",
              "      <td>4</td>\n",
              "      <td>train_spectrograms/55011312.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89380</th>\n",
              "      <td>577794603</td>\n",
              "      <td>17</td>\n",
              "      <td>50.0</td>\n",
              "      <td>1834251506</td>\n",
              "      <td>17</td>\n",
              "      <td>50.0</td>\n",
              "      <td>3168356345</td>\n",
              "      <td>30631</td>\n",
              "      <td>Other</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>train_eegs/577794603.parquet</td>\n",
              "      <td>train_spectrograms/1834251506.parquet</td>\n",
              "      <td>Other</td>\n",
              "      <td>5</td>\n",
              "      <td>train_spectrograms/1834251506.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19744</th>\n",
              "      <td>2147495892</td>\n",
              "      <td>4</td>\n",
              "      <td>18.0</td>\n",
              "      <td>386966986</td>\n",
              "      <td>4</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2752832790</td>\n",
              "      <td>37447</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/2147495892.parquet</td>\n",
              "      <td>train_spectrograms/386966986.parquet</td>\n",
              "      <td>Seizure</td>\n",
              "      <td>0</td>\n",
              "      <td>train_spectrograms/386966986.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7165</th>\n",
              "      <td>1748851242</td>\n",
              "      <td>11</td>\n",
              "      <td>142.0</td>\n",
              "      <td>134385207</td>\n",
              "      <td>11</td>\n",
              "      <td>142.0</td>\n",
              "      <td>3389451794</td>\n",
              "      <td>61174</td>\n",
              "      <td>LPD</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/1748851242.parquet</td>\n",
              "      <td>train_spectrograms/134385207.parquet</td>\n",
              "      <td>LPD</td>\n",
              "      <td>1</td>\n",
              "      <td>train_spectrograms/134385207.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80528</th>\n",
              "      <td>985265752</td>\n",
              "      <td>6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>1632325764</td>\n",
              "      <td>6</td>\n",
              "      <td>20.0</td>\n",
              "      <td>3345309326</td>\n",
              "      <td>2427</td>\n",
              "      <td>LRDA</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>train_eegs/985265752.parquet</td>\n",
              "      <td>train_spectrograms/1632325764.parquet</td>\n",
              "      <td>LRDA</td>\n",
              "      <td>3</td>\n",
              "      <td>train_spectrograms/1632325764.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51349</th>\n",
              "      <td>866318012</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1008021540</td>\n",
              "      <td>1</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1765773820</td>\n",
              "      <td>60501</td>\n",
              "      <td>Other</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>train_eegs/866318012.parquet</td>\n",
              "      <td>train_spectrograms/1008021540.parquet</td>\n",
              "      <td>Other</td>\n",
              "      <td>5</td>\n",
              "      <td>train_spectrograms/1008021540.npy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96120 rows × 20 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
              "77135   1744516630           2                       6.0      1554060622   \n",
              "89814   3288991214           0                       0.0      1836830050   \n",
              "37810    662625553           7                      68.0       744859685   \n",
              "103265  1480985066         338                    1450.0      2063104016   \n",
              "3422    2080477284           3                      14.0        55011312   \n",
              "...            ...         ...                       ...             ...   \n",
              "89380    577794603          17                      50.0      1834251506   \n",
              "19744   2147495892           4                      18.0       386966986   \n",
              "7165    1748851242          11                     142.0       134385207   \n",
              "80528    985265752           6                      20.0      1632325764   \n",
              "51349    866318012           1                       4.0      1008021540   \n",
              "\n",
              "        spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
              "77135                    2                               6.0  3671005733   \n",
              "89814                    0                               0.0  2340601286   \n",
              "37810                    7                              68.0  2026803436   \n",
              "103265                 338                            1450.0  2691322208   \n",
              "3422                     3                              14.0  3215853517   \n",
              "...                    ...                               ...         ...   \n",
              "89380                   17                              50.0  3168356345   \n",
              "19744                    4                              18.0  2752832790   \n",
              "7165                    11                             142.0  3389451794   \n",
              "80528                    6                              20.0  3345309326   \n",
              "51349                    1                               4.0  1765773820   \n",
              "\n",
              "        patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n",
              "77135         5393          Seizure             3         0         0   \n",
              "89814        65378            Other             0         0         0   \n",
              "37810        29192          Seizure             3         1         0   \n",
              "103265        8033             GRDA             0         0         0   \n",
              "3422         50648             GRDA             0         0         0   \n",
              "...            ...              ...           ...       ...       ...   \n",
              "89380        30631            Other             1         0         0   \n",
              "19744        37447          Seizure             5         0         0   \n",
              "7165         61174              LPD             0         3         0   \n",
              "80528         2427             LRDA             0         0         0   \n",
              "51349        60501            Other             0         0         0   \n",
              "\n",
              "        lrda_vote  grda_vote  other_vote                       eeg_path  \\\n",
              "77135           0          0           0  train_eegs/1744516630.parquet   \n",
              "89814           0          0           1  train_eegs/3288991214.parquet   \n",
              "37810           1          0           0   train_eegs/662625553.parquet   \n",
              "103265          0          3           0  train_eegs/1480985066.parquet   \n",
              "3422            0          3           0  train_eegs/2080477284.parquet   \n",
              "...           ...        ...         ...                            ...   \n",
              "89380           1          0           2   train_eegs/577794603.parquet   \n",
              "19744           0          0           0  train_eegs/2147495892.parquet   \n",
              "7165            0          0           0  train_eegs/1748851242.parquet   \n",
              "80528           3          0           0   train_eegs/985265752.parquet   \n",
              "51349           0          1          14   train_eegs/866318012.parquet   \n",
              "\n",
              "                                   spect_path class_name  class_label  \\\n",
              "77135   train_spectrograms/1554060622.parquet    Seizure            0   \n",
              "89814   train_spectrograms/1836830050.parquet      Other            5   \n",
              "37810    train_spectrograms/744859685.parquet    Seizure            0   \n",
              "103265  train_spectrograms/2063104016.parquet       GRDA            4   \n",
              "3422      train_spectrograms/55011312.parquet       GRDA            4   \n",
              "...                                       ...        ...          ...   \n",
              "89380   train_spectrograms/1834251506.parquet      Other            5   \n",
              "19744    train_spectrograms/386966986.parquet    Seizure            0   \n",
              "7165     train_spectrograms/134385207.parquet        LPD            1   \n",
              "80528   train_spectrograms/1632325764.parquet       LRDA            3   \n",
              "51349   train_spectrograms/1008021540.parquet      Other            5   \n",
              "\n",
              "                              spect2_path  \n",
              "77135   train_spectrograms/1554060622.npy  \n",
              "89814   train_spectrograms/1836830050.npy  \n",
              "37810    train_spectrograms/744859685.npy  \n",
              "103265  train_spectrograms/2063104016.npy  \n",
              "3422      train_spectrograms/55011312.npy  \n",
              "...                                   ...  \n",
              "89380   train_spectrograms/1834251506.npy  \n",
              "19744    train_spectrograms/386966986.npy  \n",
              "7165     train_spectrograms/134385207.npy  \n",
              "80528   train_spectrograms/1632325764.npy  \n",
              "51349   train_spectrograms/1008021540.npy  \n",
              "\n",
              "[96120 rows x 20 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#train+valid and test in npy\n",
        "df['spect2_path'] = f'train_spectrograms/'+ df['spectrogram_id'].astype(str)+'.npy'\n",
        "test_df['spect2_path'] = f'train_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.npy'\n",
        "display(test_df)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This DataLoader first reads npy spectrogram files and extracts labeled subsamples using specified offset values. Then, it converts the spectrogram data into log spectrogram and applies the popular signal augmentation MixUp.\n",
        "\n",
        "Note that, we are converting the mono channel signal to a 3-channel signal for using \"ImageNet\" weights of pretrained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_augmenter(dim=CFG.image_size):\n",
        "    augmenters = [\n",
        "        keras_cv.layers.MixUp(alpha=2.0),\n",
        "        keras_cv.layers.RandomCutout(height_factor=(1.0, 1.0),\n",
        "                                     width_factor=(0.06, 0.1)), # freq-masking\n",
        "        keras_cv.layers.RandomCutout(height_factor=(0.06, 0.1),\n",
        "                                     width_factor=(1.0, 1.0)), # time-masking\n",
        "    ]\n",
        "    \n",
        "    def augment(img, label):\n",
        "        data = {\"images\":img, \"labels\":label}\n",
        "        for augmenter in augmenters:\n",
        "            if tf.random.uniform([]) < 0.5:\n",
        "                data = augmenter(data, training=True)\n",
        "        return data[\"images\"], data[\"labels\"]\n",
        "    \n",
        "    return augment\n",
        "\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_decoder(with_labels=True, target_size=CFG.image_size, dtype=32):\n",
        "    def decode_signal(path, offset=None):\n",
        "        # Read .npy files and process the signal\n",
        "        file_bytes = tf.io.read_file(path)\n",
        "        sig = tf.io.decode_raw(file_bytes, tf.float32)\n",
        "        sig = sig[1024//dtype:]  # Remove header tag\n",
        "        sig = tf.reshape(sig, [400, -1])\n",
        "        \n",
        "        # Extract labeled subsample from full spectrogram using \"offset\"\n",
        "        if offset is not None: \n",
        "            offset = offset // 2  # Only odd values are given\n",
        "            sig = sig[:, offset:offset+300]\n",
        "            \n",
        "            # Pad spectrogram to ensure the same input shape of [400, 300]\n",
        "            pad_size = tf.math.maximum(0, 300 - tf.shape(sig)[1])\n",
        "            sig = tf.pad(sig, [[0, 0], [0, pad_size]])\n",
        "            sig = tf.reshape(sig, [400, 300])\n",
        "        \n",
        "        # Log spectrogram \n",
        "        sig = tf.clip_by_value(sig, tf.math.exp(-4.0), tf.math.exp(8.0)) # avoid 0 in log\n",
        "        sig = tf.math.log(sig)\n",
        "        \n",
        "        # Normalize spectrogram\n",
        "        sig -= tf.math.reduce_mean(sig)\n",
        "        sig /= tf.math.reduce_std(sig) + 1e-6\n",
        "        \n",
        "        # Mono channel to 3 channels to use \"ImageNet\" weights\n",
        "        sig = tf.tile(sig[..., None], [1, 1, 3])\n",
        "        return sig\n",
        "    \n",
        "    def decode_label(label):\n",
        "        label = tf.one_hot(label, CFG.num_classes)\n",
        "        label = tf.cast(label, tf.float32)\n",
        "        label = tf.reshape(label, [CFG.num_classes])\n",
        "        return label\n",
        "    \n",
        "    def decode_with_labels(path, offset=None, label=None):\n",
        "        sig = decode_signal(path, offset)\n",
        "        label = decode_label(label)\n",
        "        return (sig, label)\n",
        "    \n",
        "    return decode_with_labels if with_labels else decode_signal\n",
        "\n",
        "\n",
        "def build_dataset(paths, offsets=None, labels=None, batch_size=32, cache=True,\n",
        "                  decode_fn=None, augment_fn=None,\n",
        "                  augment=False, repeat=True, shuffle=1024, \n",
        "                  cache_dir=\"\", drop_remainder=False):\n",
        "    if cache_dir != \"\" and cache is True:\n",
        "        os.makedirs(cache_dir, exist_ok=True)\n",
        "    \n",
        "    if decode_fn is None:\n",
        "        decode_fn = build_decoder(labels is not None)\n",
        "    \n",
        "    if augment_fn is None:\n",
        "        augment_fn = build_augmenter()\n",
        "    \n",
        "    AUTO = tf.data.experimental.AUTOTUNE\n",
        "    slices = (paths, offsets) if labels is None else (paths, offsets, labels)\n",
        "    \n",
        "    try:\n",
        "        ds = tf.data.Dataset.from_tensor_slices(slices)\n",
        "        ds = ds.map(decode_fn, num_parallel_calls=AUTO)\n",
        "        ds = ds.cache(cache_dir) if cache else ds\n",
        "        ds = ds.repeat() if repeat else ds\n",
        "        if shuffle: \n",
        "            ds = ds.shuffle(shuffle, seed=CFG.seed)\n",
        "            opt = tf.data.Options()\n",
        "            opt.experimental_deterministic = False\n",
        "            ds = ds.with_options(opt)\n",
        "        ds = ds.batch(batch_size, drop_remainder=drop_remainder)\n",
        "        ds = ds.map(augment_fn, num_parallel_calls=AUTO) if augment else ds\n",
        "        ds = ds.prefetch(AUTO)\n",
        "        return ds\n",
        "    except Exception as e:\n",
        "        print(\"Error building dataset:\", e)\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the following code snippet, the data is divided into 5 folds. Note that, the groups argument is used to prevent any overlap of patients between the training and validation sets, thus avoiding potential data leakage issues. Additionally, each split is stratified based on the class_label, ensuring a uniform distribution of class labels in each fold."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>fold</th>\n",
              "      <th colspan=\"6\" halign=\"left\">0</th>\n",
              "      <th colspan=\"4\" halign=\"left\">1</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"4\" halign=\"left\">3</th>\n",
              "      <th colspan=\"6\" halign=\"left\">4</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>class_name</th>\n",
              "      <th>GPD</th>\n",
              "      <th>GRDA</th>\n",
              "      <th>LPD</th>\n",
              "      <th>LRDA</th>\n",
              "      <th>Other</th>\n",
              "      <th>Seizure</th>\n",
              "      <th>GPD</th>\n",
              "      <th>GRDA</th>\n",
              "      <th>LPD</th>\n",
              "      <th>LRDA</th>\n",
              "      <th>...</th>\n",
              "      <th>LPD</th>\n",
              "      <th>LRDA</th>\n",
              "      <th>Other</th>\n",
              "      <th>Seizure</th>\n",
              "      <th>GPD</th>\n",
              "      <th>GRDA</th>\n",
              "      <th>LPD</th>\n",
              "      <th>LRDA</th>\n",
              "      <th>Other</th>\n",
              "      <th>Seizure</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>spectrogram_id</th>\n",
              "      <td>3899</td>\n",
              "      <td>2765</td>\n",
              "      <td>2864</td>\n",
              "      <td>2515</td>\n",
              "      <td>3653</td>\n",
              "      <td>3759</td>\n",
              "      <td>2200</td>\n",
              "      <td>3854</td>\n",
              "      <td>3599</td>\n",
              "      <td>1853</td>\n",
              "      <td>...</td>\n",
              "      <td>1935</td>\n",
              "      <td>3039</td>\n",
              "      <td>3714</td>\n",
              "      <td>3719</td>\n",
              "      <td>3358</td>\n",
              "      <td>4346</td>\n",
              "      <td>2649</td>\n",
              "      <td>3163</td>\n",
              "      <td>3244</td>\n",
              "      <td>4024</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "fold               0                                     1                    \\\n",
              "class_name       GPD  GRDA   LPD  LRDA Other Seizure   GPD  GRDA   LPD  LRDA   \n",
              "spectrogram_id  3899  2765  2864  2515  3653    3759  2200  3854  3599  1853   \n",
              "\n",
              "fold            ...     3                         4                          \\\n",
              "class_name      ...   LPD  LRDA Other Seizure   GPD  GRDA   LPD  LRDA Other   \n",
              "spectrogram_id  ...  1935  3039  3714    3719  3358  4346  2649  3163  3244   \n",
              "\n",
              "fold                    \n",
              "class_name     Seizure  \n",
              "spectrogram_id    4024  \n",
              "\n",
              "[1 rows x 30 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=CFG.seed)\n",
        "\n",
        "df[\"fold\"] = -1\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "for fold, (train_idx, valid_idx) in enumerate(\n",
        "    sgkf.split(df, y=df[\"class_label\"], groups=df[\"patient_id\"])\n",
        "):\n",
        "    df.loc[valid_idx, \"fold\"] = fold\n",
        "df.groupby([\"fold\", \"class_name\"])[[\"spectrogram_id\"]].count().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Num Train: 8503 | Num Valid: 2375\n"
          ]
        }
      ],
      "source": [
        "# Sample from full train+valid data\n",
        "sample_df = df.groupby(\"spectrogram_id\").head(1).reset_index(drop=True)\n",
        "train_df = sample_df[sample_df.fold != CFG.fold]\n",
        "valid_df = sample_df[sample_df.fold == CFG.fold]\n",
        "print(f\"# Num Train: {len(train_df)} | Num Valid: {len(valid_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Only first sample for each spectrogram_id is used in order to keep the dataset size managable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras_cv\n",
        "\n",
        "# Train\n",
        "train_paths = train_df.spect2_path.values\n",
        "train_offsets = train_df.spectrogram_label_offset_seconds.values.astype(int)\n",
        "train_labels = train_df.class_label.values\n",
        "train_ds = build_dataset(train_paths, train_offsets, train_labels, batch_size=CFG.batch_size,\n",
        "                         repeat=True, shuffle=True, augment=True, cache=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Valid\n",
        "valid_paths = valid_df.spect2_path.values\n",
        "valid_offsets = valid_df.spectrogram_label_offset_seconds.values.astype(int)\n",
        "valid_labels = valid_df.class_label.values\n",
        "valid_ds = build_dataset(valid_paths, valid_offsets, valid_labels, batch_size=CFG.batch_size,\n",
        "                         repeat=False, shuffle=False, augment=False, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 400, 300, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# print(valid_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test\n",
        "test_paths = test_df.spect2_path.values\n",
        "test_offsets = test_df.spectrogram_label_offset_seconds.values.astype(int)\n",
        "test_labels = test_df.class_label.values\n",
        "test_ds = build_dataset(test_paths, test_offsets, test_labels, batch_size=CFG.batch_size,\n",
        "                         repeat=False, shuffle=False, augment=False, cache=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 400, 300, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 6), dtype=tf.float32, name=None))>\n"
          ]
        }
      ],
      "source": [
        "# print(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "LOSS = keras.losses.KLDivergence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"image_classifier_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"image_classifier_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficient_net_v2b2_backbone     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,769,374</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">EfficientNetV2Backbone</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ avg_pool                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,454</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ efficient_net_v2b2_backbone     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,     │     \u001b[38;5;34m8,769,374\u001b[0m │\n",
              "│ (\u001b[38;5;33mEfficientNetV2Backbone\u001b[0m)        │ \u001b[38;5;34m1408\u001b[0m)                  │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ avg_pool                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ predictions (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m8,454\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,777,828</span> (33.48 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,777,828\u001b[0m (33.48 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,695,540</span> (33.17 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,695,540\u001b[0m (33.17 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">82,288</span> (321.44 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m82,288\u001b[0m (321.44 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Build Classifier\n",
        "model = keras_cv.models.ImageClassifier.from_preset(\n",
        "    CFG.preset, num_classes=CFG.num_classes\n",
        ")\n",
        "\n",
        "# Compile the model  \n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss=LOSS)\n",
        "\n",
        "# Model Sumamry\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A well-structured learning rate schedule is essential for efficient model training, ensuring optimal convergence and avoiding issues such as overshooting or stagnation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "def get_lr_callback(batch_size=8, mode='cos', epochs=10, plot=False):\n",
        "    lr_start, lr_max, lr_min = 5e-5, 6e-6 * batch_size, 1e-5\n",
        "    lr_ramp_ep, lr_sus_ep, lr_decay = 3, 0, 0.75\n",
        "\n",
        "    def lrfn(epoch):  # Learning rate update function\n",
        "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
        "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
        "        elif mode == 'exp': lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
        "        elif mode == 'step': lr = lr_max * lr_decay**((epoch - lr_ramp_ep - lr_sus_ep) // 2)\n",
        "        elif mode == 'cos':\n",
        "            decay_total_epochs, decay_epoch_index = epochs - lr_ramp_ep - lr_sus_ep + 3, epoch - lr_ramp_ep - lr_sus_ep\n",
        "            phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "            lr = (lr_max - lr_min) * 0.5 * (1 + math.cos(phase)) + lr_min\n",
        "        return lr\n",
        "\n",
        "    return keras.callbacks.LearningRateScheduler(lrfn, verbose=False)  # Create lr callback\n",
        "lr_cb = get_lr_callback(CFG.batch_size, mode=CFG.lr_mode, plot=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "ckpt_cb = keras.callbacks.ModelCheckpoint(\"best_model.keras\",\n",
        "                                         monitor='val_loss',\n",
        "                                         save_best_only=True,\n",
        "                                         save_weights_only=False,\n",
        "                                         mode='min')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/13\n",
            "     10/Unknown \u001b[1m366s\u001b[0m 33s/step - loss: 1.5142"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[57], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train_ds,\n\u001b[1;32m      3\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39mvalid_ds,\n\u001b[1;32m      4\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mepochs,\n\u001b[1;32m      5\u001b[0m                     callbacks\u001b[38;5;241m=\u001b[39m[lr_cb, ckpt_cb],\n\u001b[1;32m      6\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39mCFG\u001b[38;5;241m.\u001b[39mverbose)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1501\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1502\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1503\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1504\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1505\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1506\u001b[0m   )\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_ds,\n",
        "                    validation_data=valid_ds,\n",
        "                    epochs=CFG.epochs,\n",
        "                    callbacks=[lr_cb, ckpt_cb],\n",
        "                    verbose=CFG.verbose)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the best model\n",
        "model = keras.models.load_model(\"best_model.keras\", compile=False)\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss=LOSS)\n",
        "\n",
        "# Evaluate the model\n",
        "loss, acc = model.evaluate(test_ds, verbose=CFG.verbose)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
